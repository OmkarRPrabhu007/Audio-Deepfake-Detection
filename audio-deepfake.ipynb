{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3842332,"sourceType":"datasetVersion","datasetId":2286778},{"sourceId":11277198,"sourceType":"datasetVersion","datasetId":7050228},{"sourceId":321075,"sourceType":"modelInstanceVersion","modelInstanceId":270736,"modelId":291723}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone 'https://github.com/clovaai/aasist.git'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:16.975672Z","iopub.execute_input":"2025-04-05T13:20:16.976042Z","iopub.status.idle":"2025-04-05T13:20:17.124748Z","shell.execute_reply.started":"2025-04-05T13:20:16.975978Z","shell.execute_reply":"2025-04-05T13:20:17.123673Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'aasist' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\n\nfile_path = \"/kaggle/working/aasist/evaluation.py\"\n\n# Read the file\nwith open(file_path, \"r\") as f:\n    lines = f.readlines()\n\n# Replace deprecated np.float with float\nwith open(file_path, \"w\") as f:\n    for line in lines:\n        f.write(line.replace(\"np.float\", \"np.float64\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:19.020115Z","iopub.execute_input":"2025-04-05T13:20:19.020418Z","iopub.status.idle":"2025-04-05T13:20:19.026459Z","shell.execute_reply.started":"2025-04-05T13:20:19.020393Z","shell.execute_reply":"2025-04-05T13:20:19.025724Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"!pip install torchcontrib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:21.261630Z","iopub.execute_input":"2025-04-05T13:20:21.261927Z","iopub.status.idle":"2025-04-05T13:20:24.582450Z","shell.execute_reply.started":"2025-04-05T13:20:21.261904Z","shell.execute_reply":"2025-04-05T13:20:24.581503Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchcontrib in /usr/local/lib/python3.10/dist-packages (0.0.2)\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"import argparse\nimport json\nimport os\nimport sys\nimport warnings\nfrom importlib import import_module\nfrom pathlib import Path\nfrom shutil import copy\nfrom typing import Dict, List, Union\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torchcontrib.optim import SWA\n\nfrom aasist.data_utils import (Dataset_ASVspoof2019_train,\n                        Dataset_ASVspoof2019_devNeval, genSpoof_list)\nfrom aasist.evaluation import calculate_tDCF_EER\nfrom aasist.utils import create_optimizer, seed_worker, set_seed, str_to_bool\n\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:25.841338Z","iopub.execute_input":"2025-04-05T13:20:25.841663Z","iopub.status.idle":"2025-04-05T13:20:25.847459Z","shell.execute_reply.started":"2025-04-05T13:20:25.841633Z","shell.execute_reply":"2025-04-05T13:20:25.846599Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"config = {\n    \"database_path\": \"/kaggle/input/asvpoof-2019-dataset/LA/LA/\",\n    \"asv_score_path\": \"ASVspoof2019_LA_asv_scores/ASVspoof2019.LA.asv.eval.gi.trl.scores.txt\",\n    \"model_path\": \"./models/weights/AASIST-L.pth\",\n    \"batch_size\": 1,\n    \"num_epochs\": 1,\n    \"loss\": \"CCE\",\n    \"track\": \"LA\",\n    \"eval_all_best\": \"True\",\n    \"eval_output\": \"eval_scores_using_best_dev_model.txt\",\n    \"cudnn_deterministic_toggle\": \"True\",\n    \"cudnn_benchmark_toggle\": \"False\",\n    \"model_config\": {\n        \"architecture\": \"AASIST\",\n        \"nb_samp\": 8000,\n        \"first_conv\": 128,\n        \"filts\": [70, [1, 32], [32, 32], [32, 24], [24, 24]],\n        \"gat_dims\": [24, 32],\n        \"pool_ratios\": [0.4, 0.5, 0.7, 0.5],\n        \"temperatures\": [2.0, 2.0, 100.0, 100.0]\n    },\n    \"optim_config\": {\n        \"optimizer\": \"adam\", \n        \"amsgrad\": \"False\",\n        \"base_lr\": 0.0001,\n        \"lr_min\": 0.000005,\n        \"betas\": [0.9, 0.999],\n        \"weight_decay\": 0.0001,\n        \"scheduler\": \"cosine\"\n    }\n}\n\n\nmodel_config = config[\"model_config\"]\noptim_config = config[\"optim_config\"]\noptim_config[\"epochs\"] = config[\"num_epochs\"]\ntrack = config[\"track\"]\nassert track in [\"LA\", \"PA\", \"DF\"], \"Invalid track given\"\nif \"eval_all_best\" not in config:\n    config[\"eval_all_best\"] = \"True\"\nif \"freq_aug\" not in config:\n    config[\"freq_aug\"] = \"False\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:34.250736Z","iopub.execute_input":"2025-04-05T13:20:34.251051Z","iopub.status.idle":"2025-04-05T13:20:34.257267Z","shell.execute_reply.started":"2025-04-05T13:20:34.251027Z","shell.execute_reply":"2025-04-05T13:20:34.256375Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"# make experiment reproducible\nseed = 49\nset_seed(seed, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:37.207655Z","iopub.execute_input":"2025-04-05T13:20:37.207958Z","iopub.status.idle":"2025-04-05T13:20:37.214971Z","shell.execute_reply.started":"2025-04-05T13:20:37.207934Z","shell.execute_reply":"2025-04-05T13:20:37.214173Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# define database related paths\noutput_dir = Path('/kaggle/working/exp_result')\nprefix_2019 = \"ASVspoof2019.{}\".format(track)\ndatabase_path = Path(config[\"database_path\"])\ndev_trial_path = (database_path /\n                      \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n                          track, prefix_2019))\neval_trial_path = (\n        database_path /\n        \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n            track, prefix_2019))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:39.049048Z","iopub.execute_input":"2025-04-05T13:20:39.049335Z","iopub.status.idle":"2025-04-05T13:20:39.054108Z","shell.execute_reply.started":"2025-04-05T13:20:39.049315Z","shell.execute_reply":"2025-04-05T13:20:39.053328Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"# define model related paths\nmodel_tag = \"{}_{}_ep{}_bs{}\".format(\n        track,\n        \"AASIST\",\n        config[\"num_epochs\"], config[\"batch_size\"])\n# if args.comment:\n#     model_tag = model_tag + \"_{}\".format(acomment)\n\nmodel_tag = output_dir / model_tag\nmodel_save_path = model_tag / \"weights\"\neval_score_path = model_tag / config[\"eval_output\"]\nwriter = SummaryWriter(model_tag)\nos.makedirs(model_save_path, exist_ok=True)\n# copy(config, model_tag / \"config.conf\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:43.402179Z","iopub.execute_input":"2025-04-05T13:20:43.402461Z","iopub.status.idle":"2025-04-05T13:20:43.408929Z","shell.execute_reply.started":"2025-04-05T13:20:43.402439Z","shell.execute_reply":"2025-04-05T13:20:43.408094Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def get_model(model_config: Dict, device: torch.device):\n    \"\"\"Define DNN model architecture\"\"\"\n    module = import_module(\"aasist.models.{}\".format(model_config[\"architecture\"]))\n    _model = getattr(module, \"Model\")\n    model = _model(model_config).to(device)\n    nb_params = sum([param.view(-1).size()[0] for param in model.parameters()])\n    print(\"no. model params:{}\".format(nb_params))\n\n    return model\n\ndef get_loader(\n        database_path: str,\n        seed: int,\n        config: dict) -> List[torch.utils.data.DataLoader]:\n    \"\"\"Make PyTorch DataLoaders for train / developement / evaluation\"\"\"\n    track = config[\"track\"]\n    prefix_2019 = \"ASVspoof2019.{}\".format(track)\n\n    trn_database_path = database_path / \"ASVspoof2019_{}_train/\".format(track)\n    dev_database_path = database_path / \"ASVspoof2019_{}_dev/\".format(track)\n    eval_database_path = database_path / \"ASVspoof2019_{}_eval/\".format(track)\n\n    trn_list_path = (database_path /\n                     \"ASVspoof2019_{}_cm_protocols/{}.cm.train.trn.txt\".format(\n                         track, prefix_2019))\n    dev_trial_path = (database_path /\n                      \"ASVspoof2019_{}_cm_protocols/{}.cm.dev.trl.txt\".format(\n                          track, prefix_2019))\n    eval_trial_path = (\n        database_path /\n        \"ASVspoof2019_{}_cm_protocols/{}.cm.eval.trl.txt\".format(\n            track, prefix_2019))\n\n    d_label_trn, file_train = genSpoof_list(dir_meta=trn_list_path,\n                                            is_train=True,\n                                            is_eval=False)\n    print(\"no. training files:\", len(file_train))\n\n    train_set = Dataset_ASVspoof2019_train(list_IDs=file_train,\n                                           labels=d_label_trn,\n                                           base_dir=trn_database_path)\n    gen = torch.Generator()\n    gen.manual_seed(seed)\n    trn_loader = DataLoader(train_set,\n                            batch_size=config[\"batch_size\"],\n                            shuffle=True,\n                            drop_last=True,\n                            pin_memory=True,\n                            worker_init_fn=seed_worker,\n                            generator=gen)\n\n    _, file_dev = genSpoof_list(dir_meta=dev_trial_path,\n                                is_train=False,\n                                is_eval=False)\n    print(\"no. validation files:\", len(file_dev))\n\n    dev_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_dev,\n                                            base_dir=dev_database_path)\n    dev_loader = DataLoader(dev_set,\n                            batch_size=config[\"batch_size\"],\n                            shuffle=False,\n                            drop_last=False,\n                            pin_memory=True)\n\n    file_eval = genSpoof_list(dir_meta=eval_trial_path,\n                              is_train=False,\n                              is_eval=True)\n    eval_set = Dataset_ASVspoof2019_devNeval(list_IDs=file_eval,\n                                             base_dir=eval_database_path)\n    eval_loader = DataLoader(eval_set,\n                             batch_size=config[\"batch_size\"],\n                             shuffle=False,\n                             drop_last=False,\n                             pin_memory=True)\n\n    return trn_loader, dev_loader, eval_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:45.821918Z","iopub.execute_input":"2025-04-05T13:20:45.822251Z","iopub.status.idle":"2025-04-05T13:20:45.831529Z","shell.execute_reply.started":"2025-04-05T13:20:45.822228Z","shell.execute_reply":"2025-04-05T13:20:45.830610Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"# set device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Device: {}\".format(device))\n# if device == \"cpu\":\n#     raise ValueError(\"GPU not detected!\")\n\n# define model architecture\nmodel = get_model(model_config, device)\n\n# define dataloaders\ntrn_loader, dev_loader, eval_loader = get_loader(\n        database_path, seed, config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:49.995555Z","iopub.execute_input":"2025-04-05T13:20:49.995885Z","iopub.status.idle":"2025-04-05T13:20:50.109558Z","shell.execute_reply.started":"2025-04-05T13:20:49.995855Z","shell.execute_reply":"2025-04-05T13:20:50.108763Z"}},"outputs":[{"name":"stdout","text":"Device: cuda\nno. model params:85306\nno. training files: 25380\nno. validation files: 24844\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"# get optimizer and scheduler\noptim_config[\"steps_per_epoch\"] = len(trn_loader)\noptimizer, scheduler = create_optimizer(model.parameters(), optim_config)\noptimizer_swa = SWA(optimizer)\n\nbest_dev_eer = 1.\nbest_eval_eer = 100.\nbest_dev_tdcf = 0.05\nbest_eval_tdcf = 1.\nn_swa_update = 0  # number of snapshots of model to use in SWA\nf_log = open(model_tag / \"metric_log.txt\", \"a\")\nf_log.write(\"=\" * 5 + \"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:52.624266Z","iopub.execute_input":"2025-04-05T13:20:52.624551Z","iopub.status.idle":"2025-04-05T13:20:52.633399Z","shell.execute_reply.started":"2025-04-05T13:20:52.624530Z","shell.execute_reply":"2025-04-05T13:20:52.632510Z"}},"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"6"},"metadata":{}}],"execution_count":29},{"cell_type":"code","source":"# make directory for metric logging\nmetric_path = model_tag / \"metrics\"\nos.makedirs(metric_path, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:20:58.012539Z","iopub.execute_input":"2025-04-05T13:20:58.012873Z","iopub.status.idle":"2025-04-05T13:20:58.016969Z","shell.execute_reply.started":"2025-04-05T13:20:58.012842Z","shell.execute_reply":"2025-04-05T13:20:58.016033Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"def train_epoch(\n    trn_loader: DataLoader,\n    model,\n    optim: Union[torch.optim.SGD, torch.optim.Adam],\n    device: torch.device,\n    scheduler: torch.optim.lr_scheduler,\n    config: argparse.Namespace):\n    \"\"\"Train the model for one epoch\"\"\"\n    running_loss = 0\n    num_total = 0.0\n    ii = 0\n    model.train()\n\n    # set objective (Loss) functions\n    weight = torch.FloatTensor([0.1, 0.9]).to(device)\n    criterion = nn.CrossEntropyLoss(weight=weight)\n    for batch_x, batch_y in trn_loader:\n        batch_size = batch_x.size(0)\n        num_total += batch_size\n        ii += 1\n        batch_x = batch_x.to(device)\n        batch_y = batch_y.view(-1).type(torch.int64).to(device)\n        _, batch_out = model(batch_x, Freq_aug=str_to_bool(config[\"freq_aug\"]))\n        batch_loss = criterion(batch_out, batch_y)\n        running_loss += batch_loss.item() * batch_size\n        optim.zero_grad()\n        batch_loss.backward()\n        optim.step()\n\n        if config[\"optim_config\"][\"scheduler\"] in [\"cosine\", \"keras_decay\"]:\n            scheduler.step()\n        elif scheduler is None:\n            pass\n        else:\n            raise ValueError(\"scheduler error, got:{}\".format(scheduler))\n\n    running_loss /= num_total\n    return running_loss\n\ndef produce_evaluation_file(\n    data_loader: DataLoader,\n    model,\n    device: torch.device,\n    save_path: str,\n    trial_path: str) -> None:\n    \"\"\"Perform evaluation and save the score to a file\"\"\"\n    model.eval()\n    with open(trial_path, \"r\") as f_trl:\n        trial_lines = f_trl.readlines()\n    fname_list = []\n    score_list = []\n    for batch_x, utt_id in data_loader:\n        batch_x = batch_x.to(device)\n        with torch.no_grad():\n            _, batch_out = model(batch_x)\n            batch_score = (batch_out[:, 1]).data.cpu().numpy().ravel()\n        # add outputs\n        fname_list.extend(utt_id)\n        score_list.extend(batch_score.tolist())\n\n    assert len(trial_lines) == len(fname_list) == len(score_list)\n    with open(save_path, \"w\") as fh:\n        for fn, sco, trl in zip(fname_list, score_list, trial_lines):\n            _, utt_id, _, src, key = trl.strip().split(' ')\n            assert fn == utt_id\n            fh.write(\"{} {} {} {}\\n\".format(utt_id, src, key, sco))\n    print(\"Scores saved to {}\".format(save_path))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:21:00.710625Z","iopub.execute_input":"2025-04-05T13:21:00.710920Z","iopub.status.idle":"2025-04-05T13:21:00.722276Z","shell.execute_reply.started":"2025-04-05T13:21:00.710898Z","shell.execute_reply":"2025-04-05T13:21:00.721265Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"# Training\nfor epoch in range(config[\"num_epochs\"]):\n    print(\"Start training epoch{:03d}\".format(epoch))\n    running_loss = train_epoch(trn_loader, model, optimizer, device,\n                                scheduler, config)\n    produce_evaluation_file(dev_loader, model, device,\n                            metric_path/\"dev_score.txt\", dev_trial_path)\n    dev_eer, dev_tdcf = calculate_tDCF_EER(\n        cm_scores_file=metric_path/\"dev_score.txt\",\n        asv_score_file=database_path/config[\"asv_score_path\"],\n        output_file=metric_path/\"dev_t-DCF_EER_{}epo.txt\".format(epoch),\n        printout=False)\n    print(\"DONE.\\nLoss:{:.5f}, dev_eer: {:.3f}, dev_tdcf:{:.5f}\".format(\n        running_loss, dev_eer, dev_tdcf))\n    writer.add_scalar(\"loss\", running_loss, epoch)\n    writer.add_scalar(\"dev_eer\", dev_eer, epoch)\n    writer.add_scalar(\"dev_tdcf\", dev_tdcf, epoch)\n\n    best_dev_tdcf = min(dev_tdcf, best_dev_tdcf)\n    if best_dev_eer >= dev_eer:\n        print(\"best model find at epoch\", epoch)\n        best_dev_eer = dev_eer\n        torch.save(model.state_dict(),\n                    model_save_path / \"epoch_{}_{:03.3f}.pth\".format(epoch, dev_eer))\n\n        # do evaluation whenever best model is renewed\n        if str_to_bool(config[\"eval_all_best\"]):\n            produce_evaluation_file(eval_loader, model, device,\n                                    eval_score_path, eval_trial_path)\n            eval_eer, eval_tdcf = calculate_tDCF_EER(\n                cm_scores_file=eval_score_path,\n                asv_score_file=database_path / config[\"asv_score_path\"],\n                output_file=metric_path /\n                \"t-DCF_EER_{:03d}epo.txt\".format(epoch))\n\n            log_text = \"epoch{:03d}, \".format(epoch)\n            if eval_eer < best_eval_eer:\n                log_text += \"best eer, {:.4f}%\".format(eval_eer)\n                best_eval_eer = eval_eer\n            if eval_tdcf < best_eval_tdcf:\n                log_text += \"best tdcf, {:.4f}\".format(eval_tdcf)\n                best_eval_tdcf = eval_tdcf\n                torch.save(model.state_dict(),\n                            model_save_path / \"best.pth\")\n            if len(log_text) > 0:\n                print(log_text)\n                f_log.write(log_text + \"\\n\")\n\n        print(\"Saving epoch {} for swa\".format(epoch))\n        optimizer_swa.update_swa()\n        n_swa_update += 1\n    writer.add_scalar(\"best_dev_eer\", best_dev_eer, epoch)\n    writer.add_scalar(\"best_dev_tdcf\", best_dev_tdcf, epoch)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:49:08.354801Z","iopub.execute_input":"2025-04-05T13:49:08.355217Z","iopub.status.idle":"2025-04-05T14:20:25.744075Z","shell.execute_reply.started":"2025-04-05T13:49:08.355187Z","shell.execute_reply":"2025-04-05T14:20:25.743256Z"}},"outputs":[{"name":"stdout","text":"Start training epoch000\nScores saved to /kaggle/working/exp_result/LA_AASIST_ep1_bs1/metrics/dev_score.txt\nDONE.\nLoss:0.33871, dev_eer: 31.520, dev_tdcf:0.72630\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"print(\"Start final evaluation\")\nepoch += 1\nif n_swa_update > 0:\n    optimizer_swa.swap_swa_sgd()\n    optimizer_swa.bn_update(trn_loader, model, device=device)\nproduce_evaluation_file(eval_loader, model, device, eval_score_path,\n                        eval_trial_path)\neval_eer, eval_tdcf = calculate_tDCF_EER(cm_scores_file=eval_score_path,\n                                            asv_score_file=database_path /\n                                            config[\"asv_score_path\"],\n                                            output_file=model_tag / \"t-DCF_EER.txt\")\nf_log = open(model_tag / \"metric_log.txt\", \"a\")\nf_log.write(\"=\" * 5 + \"\\n\")\nf_log.write(\"EER: {:.3f}, min t-DCF: {:.5f}\".format(eval_eer, eval_tdcf))\nf_log.close()\n\ntorch.save(model.state_dict(),\n            model_save_path / \"swa.pth\")\n\nif eval_eer <= best_eval_eer:\n    best_eval_eer = eval_eer\nif eval_tdcf <= best_eval_tdcf:\n    best_eval_tdcf = eval_tdcf\n    torch.save(model.state_dict(),\n                model_save_path / \"best.pth\")\nprint(\"Exp FIN. EER: {:.3f}, min t-DCF: {:.5f}\".format(\n    best_eval_eer, best_eval_tdcf))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-05T13:21:18.468579Z","iopub.execute_input":"2025-04-05T13:21:18.468888Z","iopub.status.idle":"2025-04-05T13:44:52.573111Z","shell.execute_reply.started":"2025-04-05T13:21:18.468865Z","shell.execute_reply":"2025-04-05T13:44:52.572307Z"}},"outputs":[{"name":"stdout","text":"Start final evaluation\nScores saved to /kaggle/working/exp_result/LA_AASIST_ep1_bs1/eval_scores_using_best_dev_model.txt\nExp FIN. EER: 21.114, min t-DCF: 0.47297\n","output_type":"stream"}],"execution_count":32}]}